{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ba5bd1",
   "metadata": {},
   "source": [
    "# start jobs on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408c1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcloud import galvani_exec, ferranti_exec, galvani_print_logs, ferranti_print_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1061c",
   "metadata": {},
   "source": [
    "## galvani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bc8b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "\n",
      "Already up to date.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "galvani_exec(\"cd $WORK/pretrain-experiments/OLMo && git pull\")\n",
    "galvani_exec(\"cd $WORK/pretrain-experiments/pretrain-experiments && git pull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d49ca601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           2333485 a100-galv pretrain sbordt10  R      48:04      1 galvani-cn203\n",
      "           2333483 a100-galv pretrain sbordt10  R      48:36      1 galvani-cn226\n",
      "           2333482 a100-galv pretrain sbordt10  R      48:54      1 galvani-cn201\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "galvani_exec(\"squeue --me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e16a2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "galvani_exec(\"scancel 2333480\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3d75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "\n",
      "Submitted batch job 2332325\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f17b4be",
   "metadata": {},
   "source": [
    "### benchmark dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a663090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating e35c616..88d96db\n",
      "Fast-forward\n",
      " ROADMAP.md                                                   |  6 ------\n",
      " .../benchmark-dependence/evaluation.yaml                     | 12 ++++++------\n",
      " internal/galvani/pretrain_experiment_4xA100.sh               |  4 ++--\n",
      " 3 files changed, 8 insertions(+), 14 deletions(-)\n",
      "\n",
      "From github.com:sbordt/pretrain-experiments\n",
      "   e35c616..88d96db  main       -> origin/main\n",
      "\n",
      "Submitted batch job 2333573\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "galvani_exec(\"cd $WORK/pretrain-experiments/pretrain-experiments && git pull\")\n",
    "galvani_exec(\"cd $WORK/pretrain-experiments/pretrain-experiments/internal/galvani/ && sbatch pretrain_experiment_4xA100.sh \\\n",
    "             pretrain-experiments/config/train-once-answer-all/benchmark-dependence/arc_challenge.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34faaee1",
   "metadata": {},
   "source": [
    "## ferranti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc930475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "            320058 h100-ferr pretrain sbordt10  R       1:28      1 mlcbm002\n",
      "            320056 h100-ferr interact sbordt10  R    1:15:36      1 mlcbm013\n",
      "\n",
      "/home/luxburg/sbordt10/.bashrc: line 35: bind: warning: line editing not enabled\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ferranti_exec(\"squeue --me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b5e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/luxburg/sbordt10/.bashrc: line 35: bind: warning: line editing not enabled\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ferranti_exec(\"scancel 320057\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f046c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "/home/luxburg/sbordt10/.bashrc: line 35: bind: warning: line editing not enabled\n",
      "\n",
      "Submitted batch job 320058\n",
      "\n",
      "/home/luxburg/sbordt10/.bashrc: line 35: bind: warning: line editing not enabled\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ferranti_exec(\"cd /weka/luxburg/sbordt10/pretrain-experiments/pretrain-experiments && git pull\")\n",
    "ferranti_exec(\"cd /weka/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/internal/ferranti/ && sbatch pretrain_experiment_4xH100.sh config/olmo-3.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633400f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of /weka/luxburg/sbordt10/logs/pretrain-experiment/316906.err:\n",
      "Error while loading conda entry point: conda-content-trust (/lib64/libc.so.6: version `GLIBC_2.30' not found (required by /home/luxburg/sbordt10/.local/lib/python3.12/site-packages/cryptography/hazmat/bindings/_rust.abi3.so))\n",
      "Error while loading conda entry point: anaconda-cloud-auth (/lib64/libc.so.6: version `GLIBC_2.30' not found (required by /home/luxburg/sbordt10/.local/lib/python3.12/site-packages/cryptography/hazmat/bindings/_rust.abi3.so))\n",
      "slurmstepd: error: *** JOB 316906 ON mlcbm002 CANCELLED AT 2026-01-31T17:32:08 ***\n",
      "slurmstepd: error: Detected 56 oom_kill events in StepId=316906.batch. Some of the step tasks have been OOM Killed.\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Content of /weka/luxburg/sbordt10/logs/pretrain-experiment/316906.out:\n",
      "JobId=316906 JobName=olmo\n",
      "   UserId=sbordt10(4198) GroupId=luxburg(4018) MCS_label=N/A\n",
      "   Priority=17755 Nice=0 Account=luxburg QOS=normal\n",
      "   JobState=RUNNING Reason=None Dependency=(null)\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n",
      "   RunTime=00:00:11 TimeLimit=3-00:00:00 TimeMin=N/A\n",
      "   SubmitTime=2026-01-28T18:32:56 EligibleTime=2026-01-28T18:32:56\n",
      "   AccrueTime=2026-01-28T18:32:57\n",
      "   StartTime=2026-01-28T18:32:57 EndTime=2026-01-31T18:32:57 Deadline=N/A\n",
      "   PreemptEligibleTime=2026-01-28T18:33:57 PreemptTime=None\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2026-01-28T18:32:57 Scheduler=Backfill\n",
      "   Partition=h100-ferranti AllocNode:Sid=ferranti-login001:3884219\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\n",
      "   NodeList=mlcbm005\n",
      "   BatchHost=mlcbm005\n",
      "   NumNodes=1 NumCPUs=16 NumTasks=1 CPUs/Task=16 ReqB:S:C:T=0:0:*:*\n",
      "   ReqTRES=cpu=16,mem=256G,node=1,billing=205,gres/gpu=1\n",
      "   AllocTRES=cpu=16,mem=256G,node=1,billing=205,gres/gpu=1,gres/gpu:h100=1\n",
      "   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n",
      "   MinCPUsNode=16 MinMemoryNode=256G MinTmpDiskNode=0\n",
      "   Features=(null) DelayBoot=00:00:00\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n",
      "   Command=/weka/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/internal/ferranti/some_custom_1xH100_job.sh\n",
      "   WorkDir=/weka/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/internal/ferranti\n",
      "   StdErr=/weka/luxburg/sbordt10/logs/pretrain-experiment/316906.err\n",
      "   StdIn=/dev/null\n",
      "   StdOut=/weka/luxburg/sbordt10/logs/pretrain-experiment/316906.out\n",
      "   Power=\n",
      "   TresPerNode=gres/gpu:1\n",
      "   TresPerTask=cpu:16\n",
      "   \n",
      "\n",
      "Wed Jan 28 18:33:08 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:D7:00.0 Off |                    0 |\n",
      "| N/A   38C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 45.2 MB/s  0:00:00\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from flash-attn) (2.10.0+cu130)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (80.10.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (2025.10.0)\n",
      "Requirement already satisfied: cuda-bindings==13.0.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.88 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.88)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.96 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.85 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.85)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.15.1.9 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (9.15.1.9)\n",
      "Requirement already satisfied: nvidia-cublas==13.1.0.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.1.0.3)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.61 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (12.0.0.61)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.4.66 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (12.0.4.66)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.3.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (12.6.3.3)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.28.9 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (2.28.9)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.4.5 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.85 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.85)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.88 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.88)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.1.6 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (1.15.1.6)\n",
      "Requirement already satisfied: triton==3.6.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from cuda-bindings==13.0.3->torch->flash-attn) (1.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Downloading einops-0.8.2-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (pyproject.toml): started\n",
      "JobId=316906 JobName=olmo\n",
      "   UserId=sbordt10(4198) GroupId=luxburg(4018) MCS_label=N/A\n",
      "   Priority=26916 Nice=0 Account=luxburg QOS=normal\n",
      "   JobState=RUNNING Reason=None Dependency=(null)\n",
      "   Requeue=1 Restarts=1 BatchFlag=1 Reboot=0 ExitCode=0:0\n",
      "   RunTime=00:02:43 TimeLimit=3-00:00:00 TimeMin=N/A\n",
      "   SubmitTime=2026-01-30T13:36:25 EligibleTime=2026-01-30T13:56:26\n",
      "   AccrueTime=2026-01-30T13:56:55\n",
      "   StartTime=2026-01-30T13:56:55 EndTime=2026-02-02T13:56:55 Deadline=N/A\n",
      "   PreemptEligibleTime=2026-01-30T13:57:55 PreemptTime=None\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2026-01-30T13:56:55 Scheduler=Backfill\n",
      "   Partition=h100-ferranti AllocNode:Sid=ferranti-login001:3884219\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\n",
      "   NodeList=mlcbm002\n",
      "   BatchHost=mlcbm002\n",
      "   NumNodes=1 NumCPUs=16 NumTasks=1 CPUs/Task=16 ReqB:S:C:T=0:0:*:*\n",
      "   ReqTRES=cpu=16,mem=256G,node=1,billing=205,gres/gpu=1\n",
      "   AllocTRES=cpu=16,mem=256G,node=1,billing=205,gres/gpu=1,gres/gpu:h100=1\n",
      "   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n",
      "   MinCPUsNode=16 MinMemoryNode=256G MinTmpDiskNode=0\n",
      "   Features=(null) DelayBoot=00:00:00\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n",
      "   Command=/weka/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/internal/ferranti/some_custom_1xH100_job.sh\n",
      "   WorkDir=/weka/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/internal/ferranti\n",
      "   StdErr=/weka/luxburg/sbordt10/logs/pretrain-experiment/316906.err\n",
      "   StdIn=/dev/null\n",
      "   StdOut=/weka/luxburg/sbordt10/logs/pretrain-experiment/316906.out\n",
      "   Power=\n",
      "   TresPerNode=gres/gpu:1\n",
      "   TresPerTask=cpu:16\n",
      "   \n",
      "\n",
      "Fri Jan 30 13:59:38 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:D7:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             70W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 3.0 MB/s  0:00:02\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from flash-attn) (2.10.0+cu130)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (80.10.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/luxburg/sbordt10/.local/lib/python3.12/site-packages (from torch->flash-attn) (2025.10.0)\n",
      "Requirement already satisfied: cuda-bindings==13.0.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.88 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.88)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.96 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.85 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.85)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.15.1.9 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (9.15.1.9)\n",
      "Requirement already satisfied: nvidia-cublas==13.1.0.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.1.0.3)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.61 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (12.0.0.61)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.4.66 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (12.0.4.66)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.3.3 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (12.6.3.3)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.28.9 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (2.28.9)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.4.5 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.85 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.85)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.88 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (13.0.88)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.1.6 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (1.15.1.6)\n",
      "Requirement already satisfied: triton==3.6.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from torch->flash-attn) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from cuda-bindings==13.0.3->torch->flash-attn) (1.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/luxburg/sbordt10/.conda/envs/pretrain-experiments/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Downloading einops-0.8.2-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (pyproject.toml): started\n",
      "  Building wheel for flash-attn (pyproject.toml): still running...\n",
      "  Building wheel for flash-attn (pyproject.toml): still running...\n",
      "  Building wheel for flash-attn (pyproject.toml): still running...\n",
      "  Building wheel for flash-attn (pyproject.toml): still running...\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "ferranti_print_logs(\"/weka/luxburg/sbordt10/logs/pretrain-experiment\", num_files=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c027ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aec821f",
   "metadata": {},
   "source": [
    "# run the olmo 2 evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20643b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "\n",
      "Submitted batch job 2333485\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "galvani_exec(\"cd $WORK/pretrain-experiments/pretrain-experiments && git pull\")\n",
    "galvani_exec(\"cd $WORK/pretrain-experiments/pretrain-experiments/internal/galvani/ && sbatch pretrain_experiment_1xA100.sh \\\n",
    "             pretrain-experiments/config/olmo2_evaluations.yaml \\\n",
    "             --model sbordt/OLMo-2-1B-Exp-Mid25B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa34a710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of /mnt/lustre/work/luxburg/sbordt10/logs/pretrain-experiments/2333542.out:\n",
      "JobId=2333542 JobName=pretrain-exp-4xA100\n",
      "   UserId=sbordt10(4198) GroupId=luxburg(4018) MCS_label=N/A\n",
      "   Priority=61100 Nice=0 Account=luxburg QOS=normal\n",
      "   JobState=RUNNING Reason=None Dependency=(null)\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n",
      "   RunTime=00:00:00 TimeLimit=3-00:00:00 TimeMin=N/A\n",
      "   SubmitTime=2026-01-29T11:43:39 EligibleTime=2026-01-29T11:43:39\n",
      "   AccrueTime=2026-01-29T11:43:39\n",
      "   StartTime=2026-01-29T11:50:48 EndTime=2026-02-01T11:50:48 Deadline=N/A\n",
      "   PreemptEligibleTime=2026-01-29T11:51:48 PreemptTime=None\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2026-01-29T11:50:48 Scheduler=Main\n",
      "   Partition=a100-galvani AllocNode:Sid=galvani-login:3114000\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\n",
      "   NodeList=galvani-cn207\n",
      "   BatchHost=galvani-cn207\n",
      "   NumNodes=1 NumCPUs=24 NumTasks=1 CPUs/Task=24 ReqB:S:C:T=0:0:*:*\n",
      "   ReqTRES=cpu=24,mem=512G,node=1,billing=52,gres/gpu=4\n",
      "   AllocTRES=cpu=24,mem=512G,node=1,billing=52,gres/gpu=4,gres/gpu:a100=4\n",
      "   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n",
      "   MinCPUsNode=24 MinMemoryNode=512G MinTmpDiskNode=0\n",
      "   Features=(null) DelayBoot=00:00:00\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) LicensesAlloc=(null) Network=(null)\n",
      "   Command=/mnt/lustre/work/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/internal/galvani/pretrain_experiment_4xA100.sh\n",
      "   WorkDir=/mnt/lustre/work/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/internal/galvani\n",
      "   StdErr=/mnt/lustre/work/luxburg/sbordt10/logs/pretrain-experiments/2333542.err\n",
      "   StdIn=/dev/null\n",
      "   StdOut=/mnt/lustre/work/luxburg/sbordt10/logs/pretrain-experiments/2333542.out\n",
      "   TresPerNode=gres/gpu:4\n",
      "   TresPerTask=cpu=24\n",
      "   \n",
      "\n",
      "Thu Jan 29 11:50:48 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:01:00.0 Off |                    0 |\n",
      "| N/A   57C    P0             81W /  250W |       0MiB /  40960MiB |    100%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCIE-40GB          On  |   00000000:25:00.0 Off |                    0 |\n",
      "| N/A   58C    P0             77W /  250W |       0MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100-PCIE-40GB          On  |   00000000:81:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             74W /  250W |       0MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100-PCIE-40GB          On  |   00000000:C1:00.0 Off |                   87 |\n",
      "| N/A   56C    P0             77W /  250W |       0MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Error loading configuration file 'pretrain-experiments/config/train-once-answer-all/benchmark-dependence/arc_challenge.yaml': Error parsing YAML file /mnt/lustre/work/luxburg/sbordt10/pretrain-experiments/pretrain-experiments/config/train-once-answer-all/benchmark-dependence/evaluation.yaml: while parsing a block mapping\n",
      "  in \"<unicode string>\", line 23, column 7:\n",
      "        - script: olmes.py\n",
      "          ^\n",
      "expected <block end>, but found '-'\n",
      "  in \"<unicode string>\", line 29, column 7:\n",
      "          - script: olmes.py\n",
      "          ^\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Content of /mnt/lustre/work/luxburg/sbordt10/logs/pretrain-experiments/2333542.err:\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "galvani_print_logs(\"/mnt/lustre/work/luxburg/sbordt10/logs/pretrain-experiments\", num_files=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olmo-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
