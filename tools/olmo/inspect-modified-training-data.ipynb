{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58943b11",
   "metadata": {},
   "source": [
    "# Inspect the modifications to the OLMo training data performed by the pretrain-experiments package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babad8d2",
   "metadata": {},
   "source": [
    "### requires the OLMo repostitory to be setup for data insertions, like the pretrain-experiments branch in https://github.com/sbordt/OLMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea9d075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/anaconda3/envs/pretrain-experiments/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pretrain_experiments.frameworks.olmo import insert_dict_to_olmo\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-2-0425-1B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013528c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No global indices file provided, building the OLMo dataloader to get the global indices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/anaconda3/envs/pretrain-experiments/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data insertion is really quite simple. \n",
    "# \n",
    "# We first build a dictionary mapping global tokens positions to the texts (or tokens) that we want to be inserted at those positions.\n",
    "#\n",
    "# The function insert_dict_to_olmo takes this dictionary and transforms it in a format that can be easily integrated OLMo data loading pipeline.\n",
    "# Internally, this needs to build the OLMo training dataloader to get access to the global token indices file, so this takes a while.\n",
    "#\n",
    "\n",
    "olmo_config = \"../../../OLMo/configs/official-0425/OLMo2-1B-stage1.yaml\"\n",
    "\n",
    "insert_dict = {\n",
    "    0: \"<|endoftext|>This will be the first training data ever seen by OLMo!<|endoftext|>\",\n",
    "    100: \"<|endoftext|>This sentence is inserted at global token position 100.<|endoftext|>\",\n",
    "    2500: \"<|endoftext|>Another inserted sentence at position 2500.<|endoftext|>\"\n",
    "}\n",
    "\n",
    "insert_dict_to_olmo(insert_dict, olmo_config, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce71ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLMO_EXPERIMENT_INSERTIONS_FILE: /home/sebastian/Documents/GitHub/pretrain-experiments/tools/olmo/insert_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# the function insert_dict_to_olmo has created an insert_dict.pkl file and set the environment variable OLMO_EXPERIMENT_INSERTIONS_FILE to point to this file\n",
    "import os\n",
    "print(\"OLMO_EXPERIMENT_INSERTIONS_FILE:\", os.environ[\"OLMO_EXPERIMENT_INSERTIONS_FILE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c270f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can build the OLMo training dataloader and see that the inserted texts are there\n",
    "#\n",
    "# for this you need the pretrain-experiments branch of https://github.com/sbordt/OLMo which looks at the OLMO_EXPERIMENT_INSERTIONS_FILE environment variable and integrates the insertions into the training data loading pipeline\n",
    "#\n",
    "from olmo.config import TrainConfig\n",
    "from olmo.data import build_train_dataloader\n",
    "\n",
    "cfg = TrainConfig.load(olmo_config)\n",
    "cfg.device_train_batch_size = 2\n",
    "cfg.save_overwrite = True\n",
    "dataloader = build_train_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebde257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader: # load the 2 sequences of the first batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d73129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>This will be the first training data ever seen by OLMo!<|endoftext|> canal as this would enhance the canal output. Maintenance tasks on the ships and other water vessels require adequate '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0])[:200] # and the inserted text is there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrain-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
