{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83631f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from olmo_core.data import NumpyFSLDatasetConfig, NumpyDataLoaderConfig, DataMix, TokenizerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39fddb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'_http_get_bytes_range' failed attempt 1 with retriable error: HTTPSConnectionPool(host='olmo-data.org', port=443): Max retries exceeded with url: /preprocessed/dolma3-0625/v0.1-official/allenai/dolma3-tokenizer/common_crawl/adult_content/000000.npy (Caused by SSLError(SSLError(1, '[SSL] record layer failure (_ssl.c:2580)')))\n",
      "'_http_get_bytes_range' failed attempt 1 with retriable error: HTTPSConnectionPool(host='olmo-data.org', port=443): Max retries exceeded with url: /preprocessed/dolma3-0625/v0.1-official/allenai/dolma3-tokenizer/common_crawl/adult_content/000000.npy (Caused by SSLError(SSLError(1, '[SSL] record layer failure (_ssl.c:2580)')))\n",
      "'_http_get_bytes_range' failed attempt 1 with retriable error: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))\n",
      "'_http_get_bytes_range' failed attempt 1 with retriable error: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))\n",
      "'_http_get_bytes_range' failed attempt 1 with retriable error: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))\n",
      "'_http_get_bytes_range' failed attempt 1 with retriable error: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))\n",
      "'_http_get_bytes_range' failed attempt 1 with retriable error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "'_http_get_bytes_range' failed attempt 1 with retriable error: ('Connection aborted.', BrokenPipeError(32, 'Broken pipe'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 0:\n",
      "  input_ids shape: torch.Size([512, 512])\n",
      "  First 10 tokens: [11, 994, 814, 7111, 1555, 11, 430, 279, 893, 1047]\n"
     ]
    }
   ],
   "source": [
    "test_paths = [\n",
    "    \"https://olmo-data.org/preprocessed/dolma3-0625/v0.1-official/allenai/dolma3-tokenizer/common_crawl/adult_content/000000.npy\"\n",
    "]\n",
    "\n",
    "tokenizer_config = TokenizerConfig.dolma2()\n",
    "                                                                                                              \n",
    "dataset_config = NumpyFSLDatasetConfig(                                                                                                                               \n",
    "      tokenizer=tokenizer_config,                         \n",
    "      paths=test_paths,                                                                                                                                     \n",
    "      work_dir=\"./test_dir\",   \n",
    "      sequence_length=512,                                                                            \n",
    ")  \n",
    "\n",
    "dataset = dataset_config.build()\n",
    "\n",
    "data_loader_config = NumpyDataLoaderConfig(\n",
    "    global_batch_size=512 * 512,\n",
    "    seed=34521,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "data_loader = data_loader_config.build(dataset)\n",
    "\n",
    "data_loader.reshuffle(epoch=1)\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "    print(f\"\\nBatch {i}:\")\n",
    "    print(f\"  input_ids shape: {batch['input_ids'].shape}\")\n",
    "    print(f\"  First 10 tokens: {batch['input_ids'][0, :10].tolist()}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f753f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', when they looked through, that the man had finished drying himself off and was putting his clothes on. They watched until he had completely dressed, and they saw him leave the bath house.\\n\\nAs soon as he had gone, May suddenly realized that she was becoming desperate to pee. Evidently, Sally was feeling the same way, because both girls rushed into the stalls to do their business. When May came out, she met Sally coming out of the next stall.\\n\\n\"Wow, did you see the size of his dick?\" Sally giggled.\\n\\n\"Yeah,\" May replied. \"But how did you know about the knot holes?\"\\n\\n\"Oh, there are always peep holes between the men\\'s and women\\'s sides in these places,\" Sally told her. \"I\\'ve peeked through lots of them.\"\\n\\n\"Hey, that means that they can peek at us, too,\" May suddenly realized.\\n\\n\"Oh yeah, I\\'ve been peeked at lots of times,\" Sally told her. \"I usually give them a good show when I know they\\'re watching.\" May couldn\\'t believe her ears, but the idea sounded so exciting that she hoped she would get a chance to show herself off.\\n\\n\"I\\'ll bet that was Bunny\\'s dad,\" Sally guessed as they walked back toward the campsite. They didn\\'t get a chance to discuss it any further at the moment, though, because Sarah came out of the vehicle as they approached, and called for them to hurry and help them set up camp.\\n\\nThey busied themselves getting folding chairs and other equipment out of the vehicle and setting up camp. Jack returned and joined in the work. He and Dan hung a large hammock between two trees while the females arranged the camp furniture around the entrance to the big camping bus. May noticed that, for some reason, Dan seemed to have selected a place to hang the hammock which was isolated from view. It was in behind some trees and bushes, and was visible only from the bus.\\n\\nAfter they had finished arranging the campsite, Sarah commented that she could use a shower and asked the girls if they would like to join her. They got their clothes and towels and walked down to the bath house. May was thinking about the holes in the wall, and she was sure that Sally was thinking the same thing. She decided that she was going to watch the holes to see if she could tell if anyone was watching.\\n\\nThe three of them quickly undressed and went into the shower area. It was one big area, and was not divided into stalls. May turned on the shower'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/Olmo-3-1025-7B\")\n",
    "\n",
    "tokenizer.decode(batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b87156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8077199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b25147b",
   "metadata": {},
   "source": [
    "## with the actual training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200243dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from olmo_core.data import DataMix, NumpyFSLDatasetConfig, TokenizerConfig, NumpyDataLoaderConfig\n",
    "\n",
    "tokenizer_config = TokenizerConfig.dolma2()\n",
    "                                                                                                              \n",
    "dataset_config = NumpyFSLDatasetConfig.from_data_mix(                                                       \n",
    "      DataMix.OLMo_mix_0625_official,                                                                         \n",
    "      tokenizer=tokenizer_config,                         \n",
    "      mix_base_dir=\"https://olmo-data.org\",                                                                   \n",
    "      sequence_length=2048,                                                                                   \n",
    "      max_target_sequence_length=8192,                                                                        \n",
    "      work_dir=\"./OLMo_mix_0625_official\",                                                                           \n",
    ")  \n",
    "\n",
    "dataset = dataset_config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088e78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_config = NumpyDataLoaderConfig(\n",
    "    global_batch_size=8192 * 512,\n",
    "    seed=34521,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "data_loader = data_loader_config.build(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eada557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.reshuffle(epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7a8ac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mBatch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m  input_ids shape: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/OLMo-core/src/olmo_core/data/data_loader.py:297\u001b[39m, in \u001b[36mTextDataLoaderBase.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrank_batch_size\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mraise\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m(\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExpected batch size of \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrank_batch_size\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m,d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m tokens on rank \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdp_rank\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    301\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgot input IDs with shape \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m = \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m,d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    302\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/OLMo-core/src/olmo_core/data/data_loader.py:179\u001b[39m, in \u001b[36mDataLoaderBase.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    176\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    Iterate over the local rank batches.\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatches_processed\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/OLMo-core/src/olmo_core/data/data_loader.py:581\u001b[39m, in \u001b[36mNumpyDataLoaderBase._iter_batches\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    579\u001b[39m current_global_batch_size = \u001b[38;5;28mself\u001b[39m.global_batch_size\n\u001b[32m    580\u001b[39m batch_iterator = _build_batch_iterator()\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m (batch := \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    582\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[32m    584\u001b[39m     \u001b[38;5;66;03m# If batch size has changed, re-initialize the workers.\u001b[39;00m\n\u001b[32m    585\u001b[39m     \u001b[38;5;66;03m# NOTE: base class handles the logic of adjusting `self.batches_processed` when\u001b[39;00m\n\u001b[32m    586\u001b[39m     \u001b[38;5;66;03m# `self.global_batch_size` is changed through the property setter.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/olmo-core/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/olmo-core/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/olmo-core/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1434\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1433\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1436\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/olmo-core/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1263\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1264\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1278\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1279\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1280\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/olmo-core/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/olmo-core/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(data_loader):\n",
    "    print(f\"\\nBatch {i}:\")\n",
    "    print(f\"  input_ids shape: {batch['input_ids'].shape}\")\n",
    "    print(f\"  First 10 tokens: {batch['input_ids'][0, :10].tolist()}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab450fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb12be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80cb95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df85b172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olmo-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
